{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263564d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Torch is not loaded. Seq2SeqDs will not be available.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pylelemmatize\n",
    "import timeit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c70d5",
   "metadata": {},
   "source": [
    "## Benchmarking pylelemmatize mapping operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87775bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_sample = \"abcd\" * 2560000 \n",
    "non_existing_sample = \"\\t\\t\\t\\t\" * 2560000\n",
    "pcnt99_existing_sample = (\"a\"*99 + \"\\t\") * 1024 * 100\n",
    "small_sample = \"abcd\"*256\n",
    "small_alphabet = \"abcd\"\n",
    "large_alphabet = pylelemmatize.charset.mes3a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8d341",
   "metadata": {},
   "source": [
    "### Running Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb532a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for sample_size ,sample_impurity , sample in [(len(small_sample),0.,small_sample),\n",
    "                            (len(existing_sample),0.,existing_sample),\n",
    "                            (len(pcnt99_existing_sample), .01, pcnt99_existing_sample),\n",
    "                            (len(non_existing_sample),1., non_existing_sample),]:\n",
    "    for alphabet_size, alphabet_str in [[len(small_alphabet), small_alphabet],[len(large_alphabet), large_alphabet]]:\n",
    "        mapping_dict = {c:c for c in alphabet_str}\n",
    "        m1 = lambda x:''.join([mapping_dict.get(c, pylelemmatize.default_unknown_chr) for c in sample])\n",
    "        d = defaultdict(lambda: pylelemmatize.default_unknown_chr)\n",
    "        m2 = lambda x:''.join([d[c] for c in sample])\n",
    "        m3 = pylelemmatize.create_mapper(alphabet_str)\n",
    "        m4 = pylelemmatize.create_mapper(alphabet_str, mapper_type = \"generic\")\n",
    "        m1result = %timeit -o m1(sample)\n",
    "        m2result = %timeit -o m2(sample)\n",
    "        m3result = %timeit -o m3(sample)\n",
    "        m4result = %timeit -o m4(sample)\n",
    "        results[(sample_size, sample_impurity, alphabet_size)] = {\"Generic Lemmatizer\": m4result,\"Fast Lemmatizer\": m3result, \"Dict\":m1result, \"Defaultdict\": m2result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a7165",
   "metadata": {},
   "source": [
    "### Rendering benchmark results to a latex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ea7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_outputs(sample_results, sample_length, scale_by):\n",
    "    min_val = min([v.average for v in sample_results.values()])\n",
    "    res = {}\n",
    "    for k, v in  sample_results.items():\n",
    "        duration_per_byte = v.average /sample_length\n",
    "        std_per_byte = v.stdev / sample_length\n",
    "        duration = duration_per_byte * scale_by\n",
    "        std = std_per_byte * scale_by\n",
    "        value_str = f\" $ {(duration):.1f} \\\\pm {(std):.1f} $\"\n",
    "        if v.average == min_val:\n",
    "            value_str = \"\\\\boldmath{\" + value_str + \"}\"\n",
    "        res[k] = value_str\n",
    "    return res\n",
    "\n",
    "\n",
    "def render_line(parameters, results):\n",
    "    sample_length, sample_missrate, alphabet_sz = parameters\n",
    "    rendered_results = format_outputs(results, sample_length, 1024**2*1000)\n",
    "    result_str = f\" & {rendered_results['Dict']} & {rendered_results['Defaultdict']} & {rendered_results['Generic Lemmatizer']} &{rendered_results['Fast Lemmatizer']}\"\n",
    "    result_str = f\"{int(sample_length/1024)} & {sample_missrate} & {alphabet_sz} {result_str} \\\\\\\\\"\n",
    "    return result_str\n",
    "\n",
    "res_lines = []\n",
    "for parameters, measurements in results.items():\n",
    "    res_lines.append(render_line(parameters, measurements))\n",
    "\n",
    "print(\"\\\\begin{tabular}{ccc||c|c|c|c}\")\n",
    "print(\"\\\\hline\")\n",
    "print(\"\\multicolumn{3}{c||}{Experiment Parameters} & \\multicolumn{3}{c}{Benchmarked Methods (msec. \\ MB)} \\\\\\\\\")\n",
    "print(\"\"\"\\\\hline\n",
    "\\makecell{Sample\\\\\\\\Size (KB)} & \n",
    "\\makecell{Unknown\\\\\\\\Characters (\\%)} & \n",
    "\\makecell{Mapping\\\\\\\\Size} & \n",
    "\\makecell{Python\\\\\\\\dict} & \n",
    "\\makecell{Python\\\\\\\\defaultdict} & \n",
    "\\makecell{Generic\\\\\\\\Lemmatizer} & \n",
    "\\makecell{Fast\\\\\\\\Lemmatizer} \\\\\\\\\n",
    "\\\\hline\"\"\")\n",
    "print(\"\\n\".join(res_lines))\n",
    "print(\"\\\\hline\\n\\end{tabular}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00a079",
   "metadata": {},
   "source": [
    "## Comparing Pylelemmatize to choco-mufin for alphabet extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a039e891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running chomufin alphabet extraction\n",
      "100%|█████████████████████████████████████| 1124/1124 [00:00<00:00, 2592.42it/s]\n",
      "{'D', '7', 'æ', ',', ')', 'C', 'X', '-', 'P', '¶', 'A', 'T', '\\\\', 'ì', 'g', 'k', 'ɉ', 'ꝑ', 'S', 'ꝓ', '5', 'r', '0', '̀', 'x', 'j', 'Q', ']', 'ē', 'h', 'o', '?', 'È', 'v', 'i', 'e', 'p', 'ÿ', 'ꝯ', '>', '6', '\\uf2ea', 'ͦ', 'Ä', 'Ë', 'd', 'ꝙ', 'ͤ', 'B', 'Û', 'c', 'è', 'ï', 'ͥ', 'm', 'F', 'ꝝ', ';', '₰', '̄', 's', '✳', '.', 'R', 'ë', ':', 'ꝫ', 'l', 'ä', '/', '2', 'Ü', '̃', 'u', 'é', '4', 'ƺ', 'ö', 'â', 'L', 'ͧ', 'ü', '₎', 'ꝭ', 'a', 'û', 'n', 'ꝟ', 'î', 'K', 'O', 'N', '(', '_', 'z', 'Â', 'Ò', 'E', '!', 'H', '=', '[', '¬', '3', 'À', '|', '`', 'I', 'ß', 'q', '&', 'ê', 'ù', 't', 'ȝ', 'V', 'ˀ', 'ʼ', 'J', '\\uf2e9', 'Y', 'U', 'Ù', 'ͨ', 'b', '\\uf2f7', '1', 'ò', 'à', 'ͣ', 'G', 'ꝰ', 'Z', 'Ö', 'W', 'ô', 'w', '9', 'y', '8', 'f', '̂', 'á', 'M', 'ħ'}\n",
      "\n",
      "real\t0m0.547s\n",
      "user\t0m0.517s\n",
      "sys\t0m0.029s\n",
      "Running pylelemmatizer alphabet extraction\n",
      "Warning: Torch is not loaded. Seq2SeqDs will not be available.\n",
      "\n",
      " !&(),-./0123456789:;=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz|¬¶ÀÂÄÈËÒÖÙÛÜßàáâäæèéêëìîïòôöùûüÿēħƺȝɉʼˀ̀̂̃̄ͣͤͥͦͧͨ₎₰✳ꝑꝓꝙꝝꝟꝫꝭꝯꝰ\n",
      "Alphabet Length: 147\n",
      "\n",
      "real\t0m0.249s\n",
      "user\t0m1.127s\n",
      "sys\t0m0.051s\n"
     ]
    }
   ],
   "source": [
    "#!pip install chocomufin\n",
    "print(\"Running chomufin alphabet extraction\")\n",
    "!time chocomufin generate --parser txt  /tmp/koeningsfelden_expanded.csv ../../tmp/koeningsfelden/koenigsfelden_1308-1662_expanded/*.txt\n",
    "!rm /tmp/koeningsfelden_expanded.csv # if the file is there, generation behaves very differently.\n",
    "print(\"Running pylelemmatizer alphabet extraction\")\n",
    "!time ll_extract_corpus_alphabet -dont_show_histogram -corpus_files ../../tmp/koeningsfelden/koenigsfelden_1308-1662_expanded/*txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (p311)",
   "language": "python",
   "name": "p311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
